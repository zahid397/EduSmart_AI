import streamlit as st
import google.generativeai as genai
import base64, os, json
from gtts import gTTS
from fpdf import FPDF
from datetime import datetime

# ---------- Gemini API Setup ----------
api_key = st.sidebar.text_input("üîë Gemini API Key", type="password",
                                value=st.secrets.get("GOOGLE_API_KEY", ""))
if api_key:
    genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-2.5-flash")

# ---------- Voice ----------
def speak(text):
    tts = gTTS(text=text, lang="bn")
    tts.save("temp.mp3")
    with open("temp.mp3", "rb") as f:
        b64 = base64.b64encode(f.read()).decode()
    os.remove("temp.mp3")
    st.markdown(
        f"<audio autoplay><source src='data:audio/mp3;base64,{b64}' type='audio/mp3'></audio>",
        unsafe_allow_html=True
    )

def play_welcome_voice():
    msg = "‡¶π‡ßç‡¶Ø‡¶æ‡¶≤‡ßã! ‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶°‡ßÅ‡¶∏‡ßç‡¶Æ‡¶æ‡¶∞‡ßç‡¶ü ‡¶è‡¶Ü‡¶á ‡¶™‡ßç‡¶∞‡ßã‡•§ ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø?"
    tts = gTTS(text=msg, lang="bn")
    tts.save("welcome.mp3")
    with open("welcome.mp3", "rb") as f:
        b64 = base64.b64encode(f.read()).decode()
    os.remove("welcome.mp3")
    st.markdown(
        f"<audio autoplay><source src='data:audio/mp3;base64,{b64}' type='audio/mp3'></audio>",
        unsafe_allow_html=True
    )

# ---------- UI ----------
st.set_page_config(page_title="EduSmart AI Pro", page_icon="üí°", layout="centered")
st.markdown("""
<style>
.stApp{background:linear-gradient(135deg,#020617,#0f172a,#1e293b);
color:#f8fafc;font-family:'Poppins',sans-serif;}
.chat-bubble-user{background:#2563eb;color:#fff;padding:10px 16px;
border-radius:16px 16px 4px 16px;margin:6px 0;max-width:85%;display:inline-block;}
.chat-bubble-ai{background:#334155;color:#f8fafc;padding:10px 16px;
border-radius:16px 16px 16px 4px;margin:6px 0;max-width:85%;display:inline-block;}
h1,h3{text-align:center;color:#38bdf8;}
</style>
""", unsafe_allow_html=True)

if os.path.exists("logo.png"):
    st.image("logo.png", width=180)
st.markdown("<h1>üèÜ EduSmart AI Pro üí°</h1>", unsafe_allow_html=True)
st.markdown("<h3>Learn ‚Ä¢ Solve ‚Ä¢ Search ‚Äî Powered by Gemini 2.5 Flash ‚ö°</h3>", unsafe_allow_html=True)
play_welcome_voice()

# ---------- Memory ----------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ---------- Smart Reply (Final Fixed Version) ----------
def smart_reply(prompt):
    sys = (
        "You are EduSmart AI Pro ‚Äî a bilingual tutor (Bangla/English). "
        "Give factual, clear, educational answers using Google Grounding when needed. "
        "If you don‚Äôt know, say so politely."
    )
    try:
        r = model.generate_content(sys + "\n\nUser: " + prompt, tools=[{"name": "google_search"}])

        # ‚úÖ Step 1: Normal text output
        if hasattr(r, "text") and r.text:
            return r.text.strip()

        # ‚úÖ Step 2: Candidate-based structure
        if hasattr(r, "candidates"):
            for c in r.candidates:
                if hasattr(c, "content") and hasattr(c.content, "parts"):
                    for p in c.content.parts:
                        if hasattr(p, "text") and p.text:
                            return p.text.strip()
                        elif hasattr(p, "function_call"):
                            try:
                                func_data = json.dumps(p.function_call, ensure_ascii=False)
                                return f"üîß Gemini used an internal function call:\n\n{func_data}"
                            except:
                                return "‚öôÔ∏è Gemini internally used a function. Please rephrase."

        # ‚úÖ Step 3: Unknown structure
        return "ü§î ‡¶Ü‡¶Æ‡¶ø ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶®‡¶á, ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡¶ü‡¶æ ‡¶è‡¶ï‡¶ü‡ßÅ ‡¶≠‡¶ø‡¶®‡ßç‡¶®‡¶≠‡¶æ‡¶¨‡ßá ‡¶¨‡¶≤‡ßã‡•§"

    except Exception as e:
        # ‚úÖ Step 4: Fully safe fallback
        return f"‚ö†Ô∏è ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ ‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø: {str(e)}"

# ---------- Chat Display ----------
for role, msg in st.session_state.chat_history[-10:]:
    css = "chat-bubble-user" if role == "user" else "chat-bubble-ai"
    st.markdown(f"<div class='{css}'>{msg}</div>", unsafe_allow_html=True)

# ---------- Chat Input ----------
if user_input := st.chat_input("‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶≤‡¶ø‡¶ñ‡ßã..."):
    st.session_state.chat_history.append(("user", user_input))
    with st.spinner("‡¶≠‡¶æ‡¶¨‡¶õ‡¶ø... ü§î"):
        ans = smart_reply(user_input)
        st.session_state.chat_history.append(("ai", ans))
        st.markdown(f"<div class='chat-bubble-ai'>{ans}</div>", unsafe_allow_html=True)
        speak(ans)
    st.rerun()

# ---------- PDF Export ----------
if st.button("üìÑ Save Chat as PDF"):
    pdf = FPDF(); pdf.add_page(); pdf.set_font("Arial", size=12)
    pdf.cell(200,10,"EduSmart AI Pro Chat History",ln=True,align="C")
    pdf.cell(200,10,f"Saved: {datetime.now()}",ln=True); pdf.ln(10)
    for r,m in st.session_state.chat_history:
        prefix = "üë§ You:" if r=="user" else "ü§ñ AI:"
        pdf.multi_cell(0,8,f"{prefix} {m}")
        pdf.ln(2)
    pdf.output("chat.pdf")
    with open("chat.pdf","rb") as f:
        st.download_button("‚¨áÔ∏è Download PDF", f, "EduSmart_Chat.pdf")
